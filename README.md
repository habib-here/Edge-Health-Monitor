# üõ°Ô∏è Edge Health Monitor

**Lightweight, zero-dependency system health monitoring for air-gapped and edge environments.**

A containerized producer‚Äìconsumer pipeline that collects real-time system metrics (CPU, memory, disk, top processes), streams them over raw TCP, and performs threshold-based alerting ‚Äî all using native Linux utilities. No cloud agents, no external dependencies, no outbound internet required.

---

## Why This Exists

Enterprise monitoring stacks like **Datadog**, **Prometheus**, or **New Relic** are powerful ‚Äî but they assume internet connectivity, open egress, and agent installation privileges. In many real-world environments, these assumptions don't hold:

| Environment | Constraint |
|---|---|
| üè≠ **Industrial / OT Networks** | Air-gapped, no internet, strict change control |
| üõ∞Ô∏è **Edge / IoT Deployments** | Limited bandwidth, intermittent connectivity |
| üîí **Classified / Secure Enclaves** | No third-party agents allowed |
| üß™ **Embedded / Minimal Systems** | No package managers, minimal disk/RAM |
| üèóÔ∏è **Temporary Infrastructure** | Short-lived VMs, test rigs, staging environments |

**Edge Health Monitor** was built to fill this gap: a self-contained, auditable, infrastructure-as-code monitoring solution that runs entirely within your perimeter.

---

## üìå Table of Contents

- [Architecture](#architecture)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Configuration](#configuration)
- [Screenshots](#screenshots)
- [How It Works](#how-it-works)
- [Use Cases](#use-cases)
- [License](#license)

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         TCP/5000          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Producer Node (VM1)    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫   ‚îÇ   Consumer Node (VM2)    ‚îÇ
‚îÇ                          ‚îÇ                           ‚îÇ                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   healthcheck.sh   ‚îÇ  ‚îÇ     CSV metrics stream    ‚îÇ  ‚îÇ   receiver.sh      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CPU %           ‚îÇ  ‚îÇ                           ‚îÇ  ‚îÇ  ‚Ä¢ Listens on :5000‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Memory %        ‚îÇ  ‚îÇ                           ‚îÇ  ‚îÇ  ‚Ä¢ Appends to log  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Disk %          ‚îÇ  ‚îÇ                           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Top 3 processes ‚îÇ  ‚îÇ                           ‚îÇ           ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ                          ‚îÇ                           ‚îÇ  ‚îÇ   analyze.sh       ‚îÇ  ‚îÇ
‚îÇ  Docker Container        ‚îÇ                           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ
‚îÇ  (producer-node-01)      ‚îÇ                           ‚îÇ  ‚îÇ  ‚Ä¢ Avg CPU / Mem   ‚îÇ  ‚îÇ
‚îÇ                          ‚îÇ                           ‚îÇ  ‚îÇ  ‚Ä¢ Max Disk usage  ‚îÇ  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ  ‚îÇ  ‚Ä¢ Alert if > 40%  ‚îÇ  ‚îÇ
                                                       ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                                                       ‚îÇ                          ‚îÇ
                                                       ‚îÇ  Docker Container        ‚îÇ
                                                       ‚îÇ  (consumer-node-01)      ‚îÇ
                                                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key design decisions:**
- **No service discovery** ‚Äî producer pushes directly to a known IP (suitable for static, air-gapped topologies)
- **No external libraries** ‚Äî everything runs on `coreutils`, `procps`, `awk`, and `netcat`
- **No cloud dependencies** ‚Äî data never leaves your network

---

## Features

| Feature | Description |
|---|---|
| **Real-Time Metrics** | CPU, memory, and disk usage sampled every 5 seconds |
| **Process Forensics** | Captures the top 3 CPU-consuming processes (PID, name, CPU%) per sample |
| **Raw TCP Streaming** | Metrics streamed via `netcat` ‚Äî no HTTP stack, no TLS overhead |
| **Threshold Alerting** | Flags `ALERT` when CPU or memory exceeds configurable threshold (default 40%) |
| **Persistent Logging** | All metrics and summaries persisted to Docker volumes for offline review |
| **One-Command Deploy** | `docker compose up -d --build` on each node ‚Äî nothing else to install |
| **Cron-Ready Analysis** | Schedule periodic summaries with a single `crontab` entry |
| **Fully Auditable** | ~130 lines of Bash total ‚Äî easily reviewed for security compliance |

---

## Tech Stack

| Layer | Technology |
|---|---|
| **Base OS** | Ubuntu 22.04 (Docker image) |
| **Scripting** | Bash (POSIX-compliant) |
| **Containerization** | Docker & Docker Compose |
| **Networking** | `netcat` (raw TCP sockets) |
| **Monitoring** | `top`, `ps`, `free`, `df`, `awk` |
| **Scheduling** | `cron` |

**Total image size:** ~75 MB per node (Ubuntu minimal + coreutils)

---

## Project Structure

```
.
‚îú‚îÄ‚îÄ vm1/                        # Producer node
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Ubuntu 22.04 + monitoring tools
‚îÇ   ‚îú‚îÄ‚îÄ compose.yml             # Docker Compose service definition
‚îÇ   ‚îî‚îÄ‚îÄ healthcheck.sh          # Metric collection & TCP streaming
‚îÇ
‚îú‚îÄ‚îÄ vm2/                        # Consumer node
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Ubuntu 22.04 + analysis tools
‚îÇ   ‚îú‚îÄ‚îÄ compose.yml             # Docker Compose service definition
‚îÇ   ‚îú‚îÄ‚îÄ receiver.sh             # TCP listener ‚Äî logs incoming metrics
‚îÇ   ‚îî‚îÄ‚îÄ analyze.sh              # Computes averages, detects anomalies
‚îÇ
‚îú‚îÄ‚îÄ screenshots/                # Execution evidence & demo output
‚îÇ   ‚îú‚îÄ‚îÄ 1_health.png
‚îÇ   ‚îú‚îÄ‚îÄ 2_summary.png
‚îÇ   ‚îú‚îÄ‚îÄ Consumer.png
‚îÇ   ‚îî‚îÄ‚îÄ Producer.png
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## Getting Started

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/) (v20.10+)
- [Docker Compose](https://docs.docker.com/compose/install/) (v2.0+)
- Two machines (physical, VMs, or containers) on the same network segment

### 1. Deploy the Consumer Node

```bash
cd vm2
docker compose up -d --build
```

The consumer starts listening on TCP port **5000**, ready to ingest metrics.

### 2. Deploy the Producer Node

> **‚öôÔ∏è Configure the target IP first:** Edit `vm1/healthcheck.sh` and set `HOST` to the consumer node's IP address.

```bash
cd vm1
docker compose up -d --build
```

The producer begins collecting and streaming metrics immediately.

### 3. Verify the Pipeline

```bash
# Watch producer output in real time
docker logs -f producer-node-01

# Confirm data is arriving at the consumer
docker exec consumer-node-01 cat /data/received_node-01.log

# Run analysis
docker exec consumer-node-01 /app/analyze.sh
```

### 4. Schedule Periodic Analysis (Optional)

```bash
crontab -e
# Add:
*/5 * * * * docker exec consumer-node-01 /app/analyze.sh >> /var/log/edge-health-summary.log 2>&1
```

---

## Configuration

All configuration lives in the scripts ‚Äî no config files or environment variables to manage.

| Parameter | File | Default | Description |
|---|---|---|---|
| `HOST` | `vm1/healthcheck.sh` | `192.168.31.134` | Consumer node IP address |
| `PORT` | `vm1/healthcheck.sh` | `5000` | TCP port for metric streaming |
| `LISTEN_PORT` | `vm2/compose.yml` | `5000` | Exposed port on the consumer |
| `sleep` interval | `vm1/healthcheck.sh` | `5s` | Metric sampling frequency |
| Alert threshold | `vm2/analyze.sh` | `40%` | CPU / Memory alert trigger |
| `NODE_ID` | All scripts | `node-01` | Node identifier for log file naming |

> **Scaling to multiple nodes?** Deploy additional producer instances with unique `NODE_ID` values, all pointing to the same consumer.

---

## Screenshots

### Producer Node ‚Äî Live Metric Collection
![Producer node streaming real-time health metrics](screenshots/Producer.png)

### Producer ‚Äî Health Log Output
![Health metrics log output from the producer](screenshots/1_health.png)

### Consumer Node ‚Äî Data Ingestion
![Consumer node receiving and logging incoming metrics](screenshots/Consumer.png)

### Analysis ‚Äî Summary & Alerting
![Analysis output showing computed averages and alert status](screenshots/2_summary.png)

---

## How It Works

### 1. Collection (Producer)
`healthcheck.sh` runs in an infinite loop inside the producer container:
- **CPU:** Parsed from `top -bn1` (100 ‚àí idle%)
- **Memory:** Computed via `free -m` (used / total √ó 100)
- **Disk:** Root filesystem usage from `df -P /`
- **Processes:** Top 3 CPU consumers from `ps -eo pid,comm,pcpu`

Each sample is formatted as a CSV line and both logged locally and pushed over TCP.

### 2. Ingestion (Consumer)
`receiver.sh` binds to a TCP port using `netcat` in listen mode. Every incoming line is appended to a persistent log file on the Docker volume ‚Äî no parsing, no processing overhead at ingestion time.

### 3. Analysis (Consumer)
`analyze.sh` processes the accumulated log with `awk`:
- Computes **average CPU** and **average memory** across all samples
- Tracks **peak disk usage**
- Emits **ALERT** if any sample exceeds the configured threshold

This can run on-demand or on a `cron` schedule.

---

## Use Cases

- **Factory floor monitoring** ‚Äî Track machine health without exposing OT networks to the internet
- **Remote site telemetry** ‚Äî Collect metrics from edge nodes with intermittent connectivity
- **Secure environment auditing** ‚Äî Fully auditable Bash scripts, no binary agents to vet
- **Temporary infrastructure** ‚Äî Spin up monitoring in minutes for test labs, staging, or demos
- **Embedded systems** ‚Äî Runs on any Linux system with Bash and Docker ‚Äî no runtime dependencies

---

## License

This project is open-source and available under the [MIT License](LICENSE).

---

<p align="center">
  Built with üêß Linux, üê≥ Docker, and pure Bash ‚Äî no agents, no cloud, no compromises.
</p>
