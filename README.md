<p align="center">
  <h1 align="center">ğŸ›¡ï¸ Edge Health Monitor</h1>
  <p align="center">
    <strong>Lightweight, zero-dependency system health monitoring for air-gapped and edge environments.</strong>
  </p>
  <p align="center">
    <a href="#getting-started"><img src="https://img.shields.io/badge/Quick_Start-â–¶-2ea44f?style=for-the-badge" alt="Quick Start"></a>
    <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue?style=for-the-badge" alt="License: MIT"></a>
    <a href="#"><img src="https://img.shields.io/badge/Platform-Linux-yellow?style=for-the-badge&logo=linux&logoColor=white" alt="Platform: Linux"></a>
    <a href="#"><img src="https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker Ready"></a>
    <a href="#"><img src="https://img.shields.io/badge/Dependencies-Zero-brightgreen?style=for-the-badge" alt="Zero Dependencies"></a>
  </p>
</p>

---

A containerized **producerâ€“consumer pipeline** that collects real-time system metrics (CPU, memory, disk, top processes), streams them over raw TCP, and performs threshold-based alerting â€” all using native Linux utilities. No cloud agents, no external dependencies, no outbound internet required.

---

## Why This Exists

Enterprise monitoring stacks like **Datadog**, **Prometheus**, or **New Relic** are powerful â€” but they assume internet connectivity, open egress, and agent installation privileges. In many real-world environments, these assumptions don't hold:

| Environment | Constraint |
|:---|:---|
| ğŸ­ **Industrial / OT Networks** | Air-gapped, no internet, strict change control |
| ğŸ›°ï¸ **Edge / IoT Deployments** | Limited bandwidth, intermittent connectivity |
| ğŸ”’ **Classified / Secure Enclaves** | No third-party agents allowed |
| ğŸ§ª **Embedded / Minimal Systems** | No package managers, minimal disk/RAM |
| ğŸ—ï¸ **Temporary Infrastructure** | Short-lived VMs, test rigs, staging environments |

**Edge Health Monitor** was built to fill this gap: a self-contained, auditable, infrastructure-as-code monitoring solution that runs entirely within your perimeter.

---

## Table of Contents

- [Architecture](#architecture)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Configuration](#configuration)
- [Screenshots](#screenshots)
- [How It Works](#how-it-works)
- [Use Cases](#use-cases)
- [License](#license)

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         TCP/5000          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer Node (VM1)    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Consumer Node (VM2)    â”‚
â”‚                          â”‚                           â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   healthcheck.sh   â”‚  â”‚     CSV metrics stream    â”‚  â”‚   receiver.sh      â”‚  â”‚
â”‚  â”‚                    â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º    â”‚  â”‚                    â”‚  â”‚
â”‚  â”‚  â€¢ CPU %           â”‚  â”‚                           â”‚  â”‚  â€¢ Listens on :5000â”‚  â”‚
â”‚  â”‚  â€¢ Memory %        â”‚  â”‚                           â”‚  â”‚  â€¢ Appends to log  â”‚  â”‚
â”‚  â”‚  â€¢ Disk %          â”‚  â”‚                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚  â€¢ Top 3 processes â”‚  â”‚                           â”‚           â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                          â”‚                           â”‚  â”‚   analyze.sh       â”‚  â”‚
â”‚  Docker Container        â”‚                           â”‚  â”‚                    â”‚  â”‚
â”‚  (producer-node-01)      â”‚                           â”‚  â”‚  â€¢ Avg CPU / Mem   â”‚  â”‚
â”‚                          â”‚                           â”‚  â”‚  â€¢ Max Disk usage  â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚  â”‚  â€¢ Alert if > 40%  â”‚  â”‚
                                                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                                       â”‚                          â”‚
                                                       â”‚  Docker Container        â”‚
                                                       â”‚  (consumer-node-01)      â”‚
                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key design decisions:**

- **No service discovery** â€” producer pushes directly to a known IP (suitable for static, air-gapped topologies)
- **No external libraries** â€” everything runs on `coreutils`, `procps`, `awk`, and `netcat`
- **No cloud dependencies** â€” data never leaves your network

### Sequence Diagram

![Sequence Diagram](screenshots/Sequence%20Diagram.png)

---

## Features

| Feature | Description |
|:---|:---|
| **Real-Time Metrics** | CPU, memory, and disk usage sampled every 5 seconds |
| **Process Forensics** | Captures the top 3 CPU-consuming processes (PID, name, CPU%) per sample |
| **Raw TCP Streaming** | Metrics streamed via `netcat` â€” no HTTP stack, no TLS overhead |
| **Threshold Alerting** | Flags `ALERT` when CPU or memory exceeds configurable threshold (default 40%) |
| **Persistent Logging** | All metrics and summaries persisted to Docker volumes for offline review |
| **One-Command Deploy** | `docker compose up -d --build` on each node â€” nothing else to install |
| **Cron-Ready Analysis** | Schedule periodic summaries with a single `crontab` entry |
| **Fully Auditable** | ~130 lines of Bash total â€” easily reviewed for security compliance |

---

## Tech Stack

| Layer | Technology |
|:---|:---|
| **Base OS** | Ubuntu 22.04 (Docker image) |
| **Scripting** | Bash (POSIX-compliant) |
| **Containerization** | Docker & Docker Compose |
| **Networking** | `netcat` (raw TCP sockets) |
| **Monitoring** | `top`, `ps`, `free`, `df`, `awk` |
| **Scheduling** | `cron` |

> [!TIP]
> **Total image size:** ~75 MB per node (Ubuntu minimal + coreutils). No runtimes, no interpreters â€” just the kernel and shell.

---

## Project Structure

```
.
â”œâ”€â”€ vm1/                        # Producer node
â”‚   â”œâ”€â”€ Dockerfile              # Ubuntu 22.04 + monitoring tools
â”‚   â”œâ”€â”€ compose.yml             # Docker Compose service definition
â”‚   â””â”€â”€ healthcheck.sh          # Metric collection & TCP streaming
â”‚
â”œâ”€â”€ vm2/                        # Consumer node
â”‚   â”œâ”€â”€ Dockerfile              # Ubuntu 22.04 + analysis tools
â”‚   â”œâ”€â”€ compose.yml             # Docker Compose service definition
â”‚   â”œâ”€â”€ receiver.sh             # TCP listener â€” logs incoming metrics
â”‚   â””â”€â”€ analyze.sh              # Computes averages, detects anomalies
â”‚
â”œâ”€â”€ screenshots/                # Execution evidence & demo output
â”‚   â”œâ”€â”€ 1_health.png
â”‚   â”œâ”€â”€ 2_summary.png
â”‚   â”œâ”€â”€ Consumer.png
â”‚   â””â”€â”€ Producer.png
â”‚
â””â”€â”€ README.md
```

---

## Getting Started

### Prerequisites

| Requirement | Version |
|:---|:---|
| [Docker](https://docs.docker.com/get-docker/) | v20.10+ |
| [Docker Compose](https://docs.docker.com/compose/install/) | v2.0+ |
| Network | Two machines (physical, VMs, or containers) on the same segment |

### 1. Deploy the Consumer Node

```bash
cd vm2
docker compose up -d --build
```

The consumer starts listening on TCP port **5000**, ready to ingest metrics.

### 2. Deploy the Producer Node

> [!IMPORTANT]
> **Configure the target IP first:** Edit `vm1/healthcheck.sh` and set the `HOST` variable to the consumer node's IP address before building.

```bash
cd vm1
docker compose up -d --build
```

The producer begins collecting and streaming metrics immediately.

### 3. Verify the Pipeline

```bash
# Watch producer output in real time
docker logs -f producer-node-01

# Confirm data is arriving at the consumer
docker exec consumer-node-01 cat /data/received_node-01.log

# Run analysis
docker exec consumer-node-01 /app/analyze.sh
```

### 4. Schedule Periodic Analysis (Optional)

```bash
crontab -e
# Add the following entry:
*/5 * * * * docker exec consumer-node-01 /app/analyze.sh >> /var/log/edge-health-summary.log 2>&1
```

---

## Configuration

All configuration lives in the scripts â€” no config files or environment variables to manage.

| Parameter | File | Default | Description |
|:---|:---|:---:|:---|
| `HOST` | `vm1/healthcheck.sh` | `192.168.31.134` | Consumer node IP address |
| `PORT` | `vm1/healthcheck.sh` | `5000` | TCP port for metric streaming |
| `LISTEN_PORT` | `vm2/compose.yml` | `5000` | Exposed port on the consumer |
| `sleep` interval | `vm1/healthcheck.sh` | `5s` | Metric sampling frequency |
| Alert threshold | `vm2/analyze.sh` | `40%` | CPU / Memory alert trigger |
| `NODE_ID` | All scripts | `node-01` | Node identifier for log file naming |

> [!NOTE]
> **Scaling to multiple nodes?** Deploy additional producer instances with unique `NODE_ID` values, all pointing to the same consumer.

---

## Screenshots

<details open>
<summary><strong>Producer Node â€” Live Metric Collection</strong></summary>
<br>

![Producer node streaming real-time health metrics](screenshots/Producer.png)

</details>

<details open>
<summary><strong>Producer â€” Health Log Output</strong></summary>
<br>

![Health metrics log output from the producer](screenshots/1_health.png)

</details>

<details open>
<summary><strong>Consumer Node â€” Data Ingestion</strong></summary>
<br>

![Consumer node receiving and logging incoming metrics](screenshots/Consumer.png)

</details>

<details open>
<summary><strong>Analysis â€” Summary & Alerting</strong></summary>
<br>

![Analysis output showing computed averages and alert status](screenshots/2_summary.png)

</details>

---

## How It Works

### 1. Collection (Producer)

`healthcheck.sh` runs in an infinite loop inside the producer container:

| Metric | Source | Method |
|:---|:---|:---|
| **CPU** | `top -bn1` | 100 âˆ’ idle% |
| **Memory** | `free -m` | used / total Ã— 100 |
| **Disk** | `df -P /` | Root filesystem usage % |
| **Processes** | `ps -eo pid,comm,pcpu` | Top 3 by CPU consumption |

Each sample is formatted as a CSV line and both logged locally and pushed over TCP.

### 2. Ingestion (Consumer)

`receiver.sh` binds to a TCP port using `netcat` in listen mode. Every incoming line is appended to a persistent log file on the Docker volume â€” no parsing, no processing overhead at ingestion time.

### 3. Analysis (Consumer)

`analyze.sh` processes the accumulated log with `awk`:

- Computes **average CPU** and **average memory** across all samples
- Tracks **peak disk usage**
- Emits **`ALERT`** if any sample exceeds the configured threshold

This can run on-demand or on a `cron` schedule.

---

## Use Cases

| Scenario | Why Edge Health Monitor |
|:---|:---|
| ğŸ­ **Factory floor monitoring** | Track machine health without exposing OT networks to the internet |
| ğŸ›°ï¸ **Remote site telemetry** | Collect metrics from edge nodes with intermittent connectivity |
| ğŸ”’ **Secure environment auditing** | Fully auditable Bash scripts â€” no binary agents to vet |
| ğŸ—ï¸ **Temporary infrastructure** | Spin up monitoring in minutes for test labs, staging, or demos |
| ğŸ”§ **Embedded systems** | Runs on any Linux system with Bash and Docker â€” no runtime dependencies |

---

## License

This project is open-source and available under the [MIT License](LICENSE).

---

<p align="center">
  <sub>Built with ğŸ§ Linux, ğŸ³ Docker, and pure Bash â€” no agents, no cloud, no compromises.</sub>
</p>
